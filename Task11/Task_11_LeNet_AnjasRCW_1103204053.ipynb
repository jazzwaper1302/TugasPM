{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOohbs6fjhk0zfRiP+Thqnn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jazzwaper1302/TugasPM/blob/main/Task11/Task_11_LeNet_AnjasRCW_1103204053.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AarS-f1AwlAu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nama : Anjas Rahmanta cahya Wijaya\n",
        "Nim : 1103204053\n",
        "Lecture 11 : Image Classification CIFAR\n",
        "Dataset : CIFAR\n",
        "Model : LeNet"
      ],
      "metadata": {
        "id": "4CRXn0k8w1SM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- LeNet Yaitu salah satu arsitektur jaringan saraf tiruan yang paling awal dan terkenal, yang dirancang oleh Yann LeCun, LÃ©on Bottou, Yoshua Bengio, dan Patrick Haffner pada tahun 1998. Arsitektur ini dikembangkan untuk pengenalan karakter tulisan tangan dan menjadi dasar bagi banyak perkembangan di bidang pembelajaran mendalam (deep learning) dan pengenalan citra.\n",
        "- Meskipun sudah lama diciptakan, LeNet menjadi dasar atau fondasi bagi banyak arsitektur CNN modern saat ini. Bahkan sampai sekarang, LeNet masih sering digunakan sebagai model pembanding (baseline) dalam berbagai tugas atau aplikasi lainnya.\n",
        "- LeNet merupakan model CNN yang sederhana namun penting karena menjadi cikal bakal berkembangnya CNN modern\n",
        "- Arsitektur LeNet-5 yang asli terdiri dari beberapa lapisan sebagai berikut:\n",
        "\n",
        "1. Input Layer: Gambar input ukuran 32x32\n",
        "2. Convolutional Layer C1: 6 filter ukuran 5x5, stride 1, dan aktivasi tanh\n",
        "3. Subsampling Layer S2: Pooling layer (average pooling) dengan ukuran 2x2 dan stride 2\n",
        "4. Convolutional Layer C3: 16 filter ukuran 5x5, stride 1, dan aktivasi tanh.\n",
        "5. Subsampling Layer S4: Pooling layer (average pooling) dengan ukuran 2x2 dan stride 2.\n",
        "6. Fully Connected Layer C5: 120 neurons, fully connected.\n",
        "7. Fully Connected Layer F6: 84 neurons, fully connected.\n",
        "8. Output Layer: 10 neurons dengan softmax untuk klasifikasi."
      ],
      "metadata": {
        "id": "wmQyAwNEw-_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "ZfxY9tS1x03B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize the images to a range of 0 to 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ],
      "metadata": {
        "id": "J4pk_AoXx4xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class names\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Function to plot images\n",
        "def plot_sample_images(x, y, class_names):\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(9, 9))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for i in np.arange(0, 9):\n",
        "        axes[i].imshow(x[i])\n",
        "        axes[i].set_title(class_names[np.argmax(y[i])])\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.subplots_adjust(wspace=1, hspace=1)\n",
        "    plt.show()\n",
        "\n",
        "# Plot sample images\n",
        "plot_sample_images(x_train, y_train, class_names)"
      ],
      "metadata": {
        "id": "JILk3l2Wx5Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(6, (5, 5), activation='tanh', input_shape=(32, 32, 3), padding='same'),\n",
        "    AveragePooling2D(),\n",
        "    Conv2D(16, (5, 5), activation='tanh', padding='valid'),\n",
        "    AveragePooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(120, activation='tanh'),\n",
        "    Dense(84, activation='tanh'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "wxpjt4UKx7Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "YeH_uTjCx9KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    batch_size=64)"
      ],
      "metadata": {
        "id": "PFYNRin8x-ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "id": "oP_TFyIRyAdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cvu5FtORyB2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Convert predictions to labels\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "report = classification_report(y_true, y_pred, target_names=class_names)\n",
        "print(report)\n",
        "\n",
        "# Function to plot sample predictions\n",
        "def plot_sample_predictions(x, y_true, y_pred, class_names):\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(9, 9))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for i in np.arange(0, 9):\n",
        "        axes[i].imshow(x[i])\n",
        "        true_label = class_names[y_true[i]]\n",
        "        pred_label = class_names[y_pred[i]]\n",
        "        axes[i].set_title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.subplots_adjust(wspace=1, hspace=1)\n",
        "    plt.show()\n",
        "\n",
        "# Plot sample predictions\n",
        "plot_sample_predictions(x_test, y_true, y_pred, class_names)"
      ],
      "metadata": {
        "id": "ly0HDwlTyDg3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}